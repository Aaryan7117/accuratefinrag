"""
Lightning AI Quick Start Script (Windows/Python version)
Run this in your Lightning AI Studio or locally
"""

import subprocess
import sys
import os

def run_cmd(cmd, shell=True):
    """Run a command and print output."""
    print(f"\n>>> {cmd}")
    result = subprocess.run(cmd, shell=shell, capture_output=False)
    return result.returncode == 0

def main():
    print("ğŸš€ Enterprise RAG System - Setup")
    print("=" * 50)
    
    # Check GPU
    print("\nğŸ“Š Checking GPU availability...")
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… GPU Available: {torch.cuda.get_device_name(0)}")
            print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("âš ï¸ No GPU detected - will use CPU (slower)")
    except ImportError:
        print("âŒ PyTorch not installed")
        run_cmd(f"{sys.executable} -m pip install torch")
    
    # Install dependencies
    print("\nğŸ“¦ Installing dependencies...")
    run_cmd(f"{sys.executable} -m pip install -r requirements.txt")
    
    # Download NLTK data
    print("\nğŸ“¥ Downloading NLTK data...")
    try:
        import nltk
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
        print("âœ… NLTK data ready")
    except Exception as e:
        print(f"âš ï¸ NLTK download failed: {e}")
    
    # Create directories
    print("\nğŸ“ Creating directories...")
    dirs = [
        "data/uploads",
        "data/processed", 
        "data/faiss_index",
        "data/bm25_index",
        "data/tables"
    ]
    for d in dirs:
        os.makedirs(d, exist_ok=True)
    print("âœ… Directories created")
    
    # Pre-download models
    print("\nğŸ¤– Pre-downloading ML models...")
    print("   This may take 5-10 minutes on first run...")
    
    try:
        os.environ['TOKENIZERS_PARALLELISM'] = 'false'
        
        print("   Loading embedding model (bge-large-en-v1.5)...")
        from sentence_transformers import SentenceTransformer
        SentenceTransformer('BAAI/bge-large-en-v1.5')
        print("   âœ… Embedding model ready")
        
        print("   Loading reranker model (bge-reranker-large)...")
        from sentence_transformers import CrossEncoder
        CrossEncoder('BAAI/bge-reranker-large')
        print("   âœ… Reranker model ready")
        
    except Exception as e:
        print(f"âš ï¸ Model download failed: {e}")
        print("   Models will download on first use")
    
    print("\n" + "=" * 50)
    print("âœ… Setup complete!")
    print("\nTo start the server:")
    print("  python -m uvicorn api.main:app --host 0.0.0.0 --port 8000")
    print("\nOr run directly:")
    print("  python api/main.py")
    print("=" * 50)
    
    # Ask to start server
    response = input("\nğŸš€ Start the server now? (y/n): ").strip().lower()
    if response == 'y':
        print("\nStarting server on http://0.0.0.0:8000 ...")
        run_cmd(f"{sys.executable} -m uvicorn api.main:app --host 0.0.0.0 --port 8000")

if __name__ == "__main__":
    main()
